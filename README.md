# pyMVP: Python Based GWAS

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

pyMVP implements GLM, MLM, FarmCPU, FarmCPU-resampling, and BLINK algorithms for genome wide association study in python. The GLM and MLM implementations in pyMVP should produce identical outputs to those provided by the R/C++ package rMVP. The FarmCPU implementation currently produces similar-but-not-identical outputs to those generated by rMVP. The FarmCPU-resampling workflow adds RMIP-based stability scoring on top of the standard FarmCPU scan. The BLINK implementation is based on Huang et al 2019. 

**Original Reference:** Yin, L., Zhang, H., Tang, Z., Xu, J., Yin, D., Zhang, Z., ... & Liu, X. (2021). rMVP: a memory-efficient, visualization-enhanced, and parallel-accelerated tool for genome-wide association study. Genomics, Proteomics & Bioinformatics doi: [10.1016/j.gpb.2020.10.007](https://doi.org/10.1016/j.gpb.2020.10.007)

**Original R package:** https://github.com/xiaolei-lab/rMVP

**BLINK Reference:** Huang, M., Liu, X., Zhou, Y., Summers, R. M., & Zhang, Z. (2019). BLINK: a package for the next level of genome-wide association studies with both individuals and markers in the millions. Gigascience doi: [10.1093/gigascience/giy154](https://doi.org/10.1093/gigascience/giy154)

**Important disclaimer:** While it project is an attempted port of the functionality of [rMVP](https://github.com/xiaolei-lab/rMVP) and BLINK, this python reimplementation is independent of the original authors and code maintainers. If this python package works for you, all credit goes to the original authors of the respective libraries and algorithms. If this package is buggy or fails, the blame is mine alone.  

## Index

- [Installation](#installation)
- [Quickstart (run_GWAS.py)](#quickstart-rungwaspy)
- [Dataset Generation](#dataset-generation)
- [Input Formats](#input-formats)
- [CLI Parameters](#cli-parameters)
- [Outputs](#outputs)
- [Performance Benchmarks](#performance-benchmarks)
- [FarmCPU Comparisons](#comparison-of-farmcpu-outputs)
- [License](#license)

## Installation

Requirements: Python 3.7+.

### Installation Steps

**Step 1: Clone the Repository**

```bash
git clone https://github.com/jschnable/pyMVP.git
cd pyMVP
```

**Step 2: Choose Installation Method**

Choose the approach that works for your system:

**Option 1: User-local Installation**

```bash
# Install to user directory (no admin/root required)
pip install -e . --user

# Install optional dependencies supporting additional file formats
pip install -e .[plink] --user
pip install -e .[vcf] --user
pip install -e .[all] --user
```

**Option 2: System-wide Override (Use with caution)**

```bash
# Override system package management restrictions
pip install -e . --break-system-packages

# Install optional dependencies supporting additional file formats
pip install -e .[plink] --break-system-packages
pip install -e .[vcf] --break-system-packages
pip install -e .[all] --break-system-packages
```

**Option 3: Virtual Environment**

```bash
# Create and activate virtual environment
python3 -m venv pymvp-env
source pymvp-env/bin/activate  # On Windows: pymvp-env\Scripts\activate

# Core install
pip install -e .

# Install optional dependencies supporting additional file formats
pip install -e .[plink]  # PLINK .bed support
pip install -e .[vcf]    # Faster VCF parsing and .bcf support
pip install -e .[all]    # All optional loaders
```


## Quickstart (run_GWAS.py)

The `scripts/run_GWAS.py` CLI runs the full pipeline: loading, QC, PCA/kinship, association (GLM/MLM/FarmCPU/BLINK/FarmCPUResampling), saving results, and optional plots.

Minimal example (CSV/TSV numeric genotypes):

```bash
python scripts/run_GWAS.py \
  --phenotype data/phenotype.csv \
  --genotype data/geno.vcf.gz \
  --output results
```

VCF/BCF (auto-detected):

```bash
python scripts/run_GWAS.py -p data/phe.csv -g data/geno.vcf.gz --methods GLM,MLM --max-missing 0.2 --min-maf 0.01
# For .bcf or faster VCF: pip install .[vcf]

# Run BLINK alongside GLM/MLM and tighten LD pruning
python scripts/run_GWAS.py -p data/phe.csv -g data/geno.vcf.gz --methods GLM,BLINK \\
  --blink-ld-threshold 0.6 --blink-bic-method even
```

PLINK .bed (requires bed-reader):

```bash
python scripts/run_GWAS.py -p data/phe.csv -g data/plink_prefix --format plink --min-maf 0.05
```

HapMap .hmp/.hmp.txt:

```bash
python scripts/run_GWAS.py -p data/phe.csv -g data/test.hmp.txt --format hapmap --snps-only
```

Multi-trait in one run (auto-detects all numeric traits):

```bash
python scripts/run_GWAS.py -p data/phe_multi.csv -g data/geno.vcf.gz --outputs all_marker_pvalues,manhattan,qq
```

![docs/images/trait3_methods_comparison.png](docs/images/trait3_methods_comparison.png)

## Input Formats

### Genetic Marker Data

pyMVP supports loading genotype data in:

* VCF/BCF (`.vcf`, `.vcf.gz`, `.vcf.bgz`, `.bcf`). The loader counts ALT alleles in each
  `GT` field, so polyploid calls like `0/1/1/1` are preserved without lossy clipping.
* PLINK `.bed` (requires matching `.bim`/`.fam`).
* HapMap `.hmp`/`.hmp.txt`.
* Numeric CSV/TSV matrices (first column sample IDs, remaining columns genotype
  dosages, missing encoded as `-9`).

For polyploid datasets encoded in numeric CSV/TSV form, store dosages as integers in the
range `0..P` (e.g. `0..4` for tetraploid, `0..6` for hexaploid) rather than fractional
values. The new `--max-genotype-dosage` flag controls how allele frequencies and MAF
filters are computed; set it to the maximum expected dosage (defaults to `2` for diploids).
When loading VCF/BCF files the loader infers ploidy from each genotype automatically, but
`--max-genotype-dosage` still governs how summary tables and cross-method comparisons
normalise MAF values.

If multiple genotype records are listed with the same sample ID, only genetic marker data the **first occurrence in the file is used**.

#### Accelerating Large Genotype Files with Caching

For very large genotype files (VCF, HapMap, CSV/TSV), initial loading can take several minutes. pyMVP provides a caching mechanism to convert these text-based formats into fast-loading binary files that dramatically speed up repeated analyses.

**Creating a cache:**

```bash
pymvp-cache-genotype -i path/to/genotype.vcf -o cache/maize_chr1
```

This command converts your genotype file into a binary `.memmap` plus sidecar metadata files:

* `cache/maize_chr1.memmap`: Contiguous int8 genotype matrix.
* `cache/maize_chr1.pymvp_cache.npz`: Metadata with shape/dtype information.
* `cache/maize_chr1.samples.txt`: Sample IDs captured during load.
* `cache/maize_chr1.map.csv`: SNP map (when the source provides one).

**Using cached genotypes:**

Once cached, point any pyMVP script directly at the metadata file:

```bash
python scripts/run_GWAS.py -p data/phe.csv -g cache/maize_chr1.pymvp_cache.npz
```

pyMVP will detect the cache and memory-map the genotype matrix instantly, bypassing text parsing entirely.

**Cache options:**

* `--format`: Explicitly specify input format if auto-detection fails.
* `--dtype`: Storage dtype (default: `int8`; use wider types for polyploids if needed).
* `--batch-size`: Number of markers to copy per chunk during cache creation.
* `--load-option KEY=VALUE`: Pass additional options to the loader (repeatable).
* `--precompute-alleles`: Pre-calculate major alleles during caching (default: off).

**Performance tip:** When loading text-format genotypes that take over 5 minutes, pyMVP will emit a warning suggesting you cache the file. Cached genotypes typically load in under a second regardless of file size.

### Phenotype Data

pyMVP expects phenotype data to be provided as a csv or tsv with one column giving sample IDs and one or more columns containing numeric phenotypes.

* pyMVP will first attempt to detect the ID column by looking for the names ID, id, IID, sample, Sample, Taxa, taxa, Genotype, genotype, Accession or accession.
* * If none of these labels are present it will assume the left-most column represents sample IDs.
* * If two or more of these labels are present the left-most column with a matching name will be used.
* All other columns are assumed to be phenotypes. Phenotypes are coerced to numeric, and all missing or non-numeric values are treated as NA.

You can customize which phenotypes are analyzed using the `--traits` parameter which allows you to provide a  comma-separated list of trait names. If `--traits` is not used all numeric traits present in the phenotype file are analyzed.

**Duplicate Sample IDs**: If multiple phenotype rows have the same individual ID, they are merged by computing the mean across rows for each trait column (missing values ignored). For example, if a phenotype file for height includes ID "Sample001" for 3 rows [1.2, 1.5, NaN], the final height value used for GWAS will be 1.35.

### Covariate Data

In addition to principal components (PCs) computed from genotype data, pyMVP supports user-supplied covariates (e.g., sex, treatment, environmental factors). Covariates are incorporated into GLM, MLM, FarmCPU, and BLINK models to control for additional sources of variation beyond population structure.

**File format:** Provide a CSV or TSV file with one ID column and one or more numeric covariate columns. ID column detection follows the same rules as phenotype files (searches for common ID headers like `ID`, `IID`, `taxa`, etc., or defaults to the leftmost column).

**Usage:**

```bash
python scripts/run_GWAS.py -p data/phe.csv -g data/geno.vcf.gz \
  --covariates data/covariates.csv \
  --covariate-columns age,sex,treatment
```

**CLI Parameters:**

- `--covariates`: Path to covariate file (CSV/TSV).
- `--covariate-columns`: Comma-separated list of column names to use as covariates. If omitted, all numeric columns (except the ID column) are used.
- `--covariate-id-column`: Explicitly specify which column contains sample IDs (optional; auto-detected by default).

**Per-trait alignment:** For each trait, pyMVP aligns phenotypes, covariates, genotypes, and PCs by sample ID. Only individuals with valid (non-missing) trait values are retained. Missing covariates are mean-imputed after alignment. The combined covariate + PC matrix is used as the design matrix for all association methods.

**Duplicate Sample IDs:** If the covariate file contains multiple rows with the same sample ID, they are merged by computing the per-ID mean for each covariate (missing values ignored), and a warning is emitted.

## CLI Parameters

**Required:**

- `--phenotype, -p`: Phenotype file (CSV/TSV with ID and one or more numeric traits).
- `--genotype, -g`: Genotype file (CSV/TSV numeric; VCF/BCF; PLINK; HapMap).

**Common options:**

- `--output, -o`: Output directory (default: `./GWAS_results`).
- `--methods`: Comma-separated list of methods to run (`GLM,MLM,FarmCPU,FarmCPUResampling,BLINK`).
- `--n-pcs`: Number of principal components (default: 3).
- `--traits`: Comma-separated list of trait names; by default, all numeric traits present in the phenotype file are analyzed.
- `--outputs`: Choose any of `all_marker_pvalues`, `significant_marker_pvalues`, `manhattan`, `qq` (comma- or space-separated).

**Covariate options:**

- `--covariates`: Path to covariate file (CSV/TSV with ID column and numeric covariates).
- `--covariate-columns`: Comma-separated list of covariate column names to include. If not specified, all numeric columns (except the ID column) are used.
- `--covariate-id-column`: Explicitly specify which column contains sample IDs (optional; auto-detected by default).

**Significance control:**

- Default: Bonferroni with `alpha=0.05` and the true number of markers.
- `--alpha`: Override alpha used for Bonferroni.
- `--n-eff`: Use an effective number of markers for Bonferroni denominator.
- `--compute-effective-tests`: Estimate the Li & Ji effective marker count (GEC-style) after loading genotypes and use it as the Bonferroni denominator. Optional tuning knobs: `--effective-test-window`, `--effective-test-corr-cutoff`, `--effective-test-gap-limit`, `--effective-test-span-limit`, `--effective-test-prune-threshold`.
- `--significance`: Fixed p-value threshold; overrides `--alpha` and `--n-eff` when provided.

**Genotype loader/QC options:**

- `--format, -f`: Force genotype format (`csv`, `tsv`, `numeric`, `vcf`, `plink`, `hapmap`). Autodetects by default.
- VCF/BCF: `--no-split-multiallelic`, `--snps-only`.
- All formats: `--drop-monomorphic`, `--max-missing`, `--min-maf`.
- `--max-genotype-dosage`: Normalise allele frequencies using this maximum
  dosage (2 for diploids, 4 for tetraploids, etc.); affects reported MAF values
  and BLINK's MAF filtering.

**FarmCPU:**
- `--max-iterations`: Maximum iterations (default: 10).

**FarmCPU Resampling (RMIP):**
- `--farmcpu-resampling-runs`: Number of FarmCPU resampling runs (X, default: 100).
- `--farmcpu-resampling-mask`: Fraction of non-missing phenotypes masked per run (Y, default: 0.1).
- `--farmcpu-resampling-significance`: Optional override for the per-run p-value threshold (defaults to Bonferroni `alpha / n_tests`).
- `--farmcpu-resampling-cluster`: Enable LD-based clustering when computing RMIP counts.
- `--farmcpu-resampling-ld-threshold`: R² threshold Z for treating markers as a single cluster (default: 0.7).
- `--farmcpu-resampling-seed`: Optional random seed to make masking reproducible.

### FarmCPU Resampling (RMIP)

The FarmCPU-resampling workflow mitigates marker instability by repeatedly running FarmCPU with random masking of phenotype values. Each run masks Y percent of the non-missing phenotypes, executes FarmCPU, and retains markers whose p-values surpass the configured significance threshold. The **resampling model inclusion probability (RMIP)** is the fraction of runs in which a marker is rediscovered. When LD clustering is enabled, markers with genotype R² ≥ Z are grouped so that each run contributes at most one hit per cluster, preventing inflated stability scores for highly correlated markers.

Outputs include an RMIP-scaled Manhattan plot (`GWAS_[TraitLabel]_FarmCPUResampling_rmip_manhattan.png`) and a trait-specific RMIP table. The RMIP table reports `SNP`, `Chr`, `Pos`, `RMIP`, and `Trait`, plus a `ClusterMembers` summary when clustering is active (cluster size and per-marker RMIP values).

By default the per-run significance threshold matches the Bonferroni-corrected alpha used for other methods (i.e., `alpha / n_tests`, where `n_tests` is either the true marker count or `--n-eff`). Supplying `--farmcpu-resampling-significance` overrides this value; the CLI emits a warning if the override is less stringent than FarmCPU's pseudo-QTN threshold because such markers cannot be retained in later FarmCPU iterations.

## Outputs

Per trait (label sanitized and uniquified):

- `GWAS_[TraitLabel]_all_results.csv` (if `all_results` selected):
  - Columns: `SNP`, `CHROM`, `POS`, `MAF`, and for each p-value based method: `[Method]_Effect`, `[Method]_SE`, `[Method]_Pvalue`, `[Method]_Passed_Bonferroni` (`yes`/`no`).
  - FarmCPU-resampling adds `[FarmCPUResampling]_RMIP` (always) and `[FarmCPUResampling]_ClusterMembers` when clustering is enabled.
- `GWAS_[TraitLabel]_significant_SNPs_p[threshold].csv` (if `significant` selected):
  - Rows passing the chosen significance threshold; includes map columns, per-method stats, and a `Method` column.
- `GWAS_[TraitLabel]_FarmCPUResampling_RMIP.csv`: RMIP summaries listing each marker or cluster, its RMIP value, trait name, and optional cluster membership details.
- Plots (if selected): `GWAS_[TraitLabel]_[Method]_manhattan.png`, `GWAS_[TraitLabel]_[Method]_qq.png`, and `GWAS_[TraitLabel]_FarmCPUResampling_rmip_manhattan.png` for RMIP summaries.

Aggregate:

- `GWAS_summary_by_trait_method.csv`: One row per trait × method with summary stats:
  - P-value methods: `n_significant` (markers passing Bonferroni), `min_pvalue`, `threshold_used`, `alpha`, `n_tests_used`.
  - FarmCPU-resampling: `n_identified`, `max_rmip`, `mean_rmip`, `cluster_mode`, `total_runs`.

Notes:

- Bonferroni-adjusted p-values (`[Method]_Pvalue_Bonf`) are reported using the chosen `n_tests_used` (true marker count or `--n-eff`).
- When `--significance` is provided, it overrides alpha/n_eff for significance calls.

## Performance Benchmarks

Based on average performance across a synthetic datasets of 1,000 samples with 250,000 genetic markers run on an Apple Laptop with an M3 Pro CPU and 36 GB of RAM and OpenBLAS installed and configured for both implementations. All values are averages across 10 traits.

| Method | pyMVP Time | rMVP Time | 
|--------|------------|-----------|
| GLM    | 0.6s       | 4.5s      | 
| MLM    | 7.8s       | 21.9s     | 
| FarmCPU| 8.9s       | 20.5s     | 

**Disclaimer**: Checked these rMVP runtimes against Kusmec 2018 and they seem reasonable, but I should do some more tests to make sure.

## Comparison of FarmCPU Outputs 

pyMVP exactly duplicates the p-values assigned to genetic markers by rMVP when using the GLM and MLM implementations. 

**However the pyMVP FarmCPU implementation does not yet precisely match the output of the rMVP FarmCPU implementation.** In a study of 10 simulated datasets, p-values assigned to true QTN and power to detect true QTN were similar in the rMVP and pyMVP implementations of FarmCPU, although the rMVP FarmCPU implementation has slightly higher average power. Could be luck or it could be some functionality we haven't been able to replicate yet. 

![docs/images/all_methods_comparison_compact.png](docs/images/farmcpu_comparison_plots.png)

**Note** In these same 10 simulated datasets, the pyMVP BLINK implementation achieves an LD-adjusted power of 0.176 (an 11% increase over the average the power of the pyMVP FarmCPU implementation) and a LD-adjusted false discovery rate of 0.02 (a 89% decrease relative to the average false discovery rate of the pyMVP FarmCPU implementation).

## Dataset Generation

pyMVP includes a comprehensive dataset generation tool for creating realistic simulated GWAS datasets with known causal variants. The generator supports configurable population structure, linkage disequilibrium patterns, MAF spectra, MAF-effect coupling, heritability control, and study designs (outbred/inbred).

**Script location**: `scripts/generate_performance_dataset.py`

Generate a test dataset:

```bash
python scripts/generate_performance_dataset.py \
  --n-samples 1000 \
  --n-snps 50000 \
  --n-qtns 50 \
  --output-dir test_dataset
```

Use simulated datasets to benchmark GWAS methods, validate power/FDR, test population structure correction, or evaluate method performance across heritability ranges.

**Full documentation**: See [docs/generate_performance_dataset.md](docs/generate_performance_dataset.md) for detailed parameter descriptions, usage examples, built-in assumptions, and troubleshooting guidance.

## License

Distributed under the MIT license. See [LICENSE](LICENSE).
